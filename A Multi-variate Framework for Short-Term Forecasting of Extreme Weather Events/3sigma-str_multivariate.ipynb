{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Framework\n",
    "\n",
    "<img src=\"./Resources/3Sigma-STR framework.png\" alt=\"3Sigma-STR Framework\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Reshape, Conv1D, GlobalMaxPooling1D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./Data\"\n",
    "results_folder = \"./Results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis + Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(data_folder):\n",
    "    \"\"\"\n",
    "    Concatenate CSV files from a specified folder and year into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Path to the folder containing the CSV files.\n",
    "        year (int): Year to filter the CSV files by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing concatenated data from the specified year.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    for file in Path(data_folder).rglob('*.csv'):\n",
    "        df = pd.read_csv(file)\n",
    "        data = pd.concat([data, df])\n",
    "\n",
    "    data = data.sort_values(by=\"Date/Time (LST)\").reset_index(drop=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(data, time_col, feature_cols, plot=True):\n",
    "    \"\"\"\n",
    "    Analyze rainfall data by checking for missing values, calculating basic statistics, and plotting the data.\n",
    "\n",
    "    Parameters:\n",
    "        rainfall_data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        time_col (str): Name of the column containing timestamps.\n",
    "        feature_cols (list): Name of the column containing precipitation amounts.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing basic statistics and missing values information.\n",
    "    \"\"\"\n",
    "    \n",
    "    data[time_col] = pd.to_datetime(data[time_col])\n",
    "\n",
    "    results = {}\n",
    "    for col in feature_cols:\n",
    "        # Check for missing values\n",
    "        missing_values = data[col].isnull().sum()\n",
    "        print(f\"Number of missing values in {col}: {missing_values}\")\n",
    "\n",
    "        # Calculate basic statistics\n",
    "        stats = data[col].describe()\n",
    "        print(f\"Basic statistics for {col}:\\n{stats}\")\n",
    "\n",
    "        results[col] = {\"missing_values\": missing_values, \"stats\": stats}\n",
    "\n",
    "        if plot:\n",
    "            # Plot the data\n",
    "            data.plot(x=time_col, y=col, title=f'{col} Over Time')\n",
    "\n",
    "        # Plot missing values\n",
    "        if missing_values > 0:\n",
    "            missing_data = data[data[col].isnull()].fillna(0)\n",
    "            missing_data.plot(x=time_col, y=col, kind='scatter', color='red', title=f'Missing Values in {col}')\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, time_col, feature_cols, remove_outliers=True):\n",
    "    \"\"\"\n",
    "    Clean the data by removing unnecessary columns, renaming columns, and optionally removing outliers.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing the data to be cleaned.\n",
    "        time_col (str): Name of the column containing timestamps.\n",
    "        feature_cols (list): Name of the column containing rainfall amounts.\n",
    "        remove_outliers (bool): Whether to remove outliers from the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing cleaned data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the index to the timestamp column\n",
    "    data[time_col] = pd.to_datetime(data[time_col])\n",
    "    data.set_index(time_col, inplace=True)\n",
    "    data = data.asfreq('h')\n",
    "\n",
    "    # Drop nan and zero values for all feature columns\n",
    "    for col in feature_cols:\n",
    "        data = data.dropna(subset=[col])\n",
    "        data = data[data[col] != 0]\n",
    "\n",
    "    if remove_outliers:\n",
    "        # Remove outliers using the IQR method\n",
    "        Q1 = data[data[col] > 0][col].quantile(0.25)\n",
    "        Q3 = data[data[col] > 0][col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define outlier bounds\n",
    "        upper_bound = Q3 + 29 * IQR\n",
    "\n",
    "        # Identify outliers\n",
    "        outliers = data[data[col] > upper_bound]\n",
    "        print(\"Upper Bound for Outliers:\", upper_bound)\n",
    "        print(\"Number of Outliers:\", len(outliers),\"\\n\")\n",
    "\n",
    "        # Remove outliers  \n",
    "        data = data[data[col] <= upper_bound]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data, feature_cols, using_decompose=True):\n",
    "    \"\"\"\n",
    "    Analyze rainfall data by calculating the correlation matrix, plotting a heatmap,\n",
    "    and performing the Augmented Dickey-Fuller test for stationarity.\n",
    "\n",
    "    Parameters:\n",
    "        rainfall_data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        time_col (str): Name of the column containing timestamps.\n",
    "        feature_cols (list): Name of the column containing precipitation amounts.\n",
    "\n",
    "    Returns:\n",
    "        dict: Results of the Augmented Dickey-Fuller test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correlation matrix \"check correlation between features\" \n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    corr_matrix = numeric_data.corr()\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f', linewidths=0.5, annot_kws={\"size\": 10, \"weight\": \"bold\"})\n",
    "\n",
    "    # Analyze each feature in feature_cols\n",
    "    for col in feature_cols:\n",
    "        # Augmented Dickey-Fuller test for stationarity\n",
    "        adf, pvalue, usedlag, nobs, critical_values, icbest = adfuller(data[col].dropna())\n",
    "        print(f\"ADF test for {col}: pvalue = {pvalue} (if above 0.05, data is not stationary)\")\n",
    "\n",
    "        # Seasonality\n",
    "        ## Boxplots General Patterns \"Yearly & Monthly\"\n",
    "        data['year'] = [h.year for h in data.index]\n",
    "        data['month'] = [h.strftime('%b') for h in data.index]\n",
    "        years = data['year'].unique()\n",
    "        months = data['month'].unique()\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        sns.boxplot(x=\"year\", y=col, data=data, ax=axs[0])\n",
    "        sns.boxplot(x=\"month\", y=col, data=data, ax=axs[1])\n",
    "        axs[0].set_title(f'Boxplots of {col} Amounts')\n",
    "        plt.show()\n",
    "        \n",
    "        if using_decompose:\n",
    "            ## Using seasonal_decompose\n",
    "            decomposed = seasonal_decompose(data[col].dropna(), model='additive', period=24*365)\n",
    "\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.subplot(411)\n",
    "            plt.plot(data[col], label='Original', color='blue')\n",
    "            plt.legend(loc='best')\n",
    "            plt.subplot(412)\n",
    "            plt.plot(decomposed.trend, label='Trend', color='blue')\n",
    "            plt.legend(loc='best')\n",
    "            plt.subplot(413)\n",
    "            plt.plot(decomposed.seasonal, label='Seasonal', color='blue')\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "    \n",
    "        autocorrelation_plot(data[col].dropna())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_categorical(data, rain_col=\"Rain Intensity\"):\n",
    "    \"\"\"\n",
    "    Analyze categorical rainfall data after sigma chart by calculating the frequency distribution,\n",
    "    plotting a heatmap of the correlation matrix, and visualizing the data.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        time_col (str): Name of the column containing timestamps.\n",
    "        rain_col (str): Name of the column containing categorical rainfall intensity.\n",
    "\n",
    "    Returns:\n",
    "        dict: Frequency distribution of the categorical data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    stats = data[rain_col].describe()\n",
    "    print(f\"Basic statistics for {rain_col}:\\n{stats}\\n\")\n",
    "\n",
    "    # Frequency distribution of categorical data\n",
    "    freq_dist = data[rain_col].value_counts(normalize=True)\n",
    "    print(f\"Frequency distribution of {rain_col}:\\n{freq_dist}\")\n",
    "\n",
    "    # Plot frequency distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=freq_dist.index, y=freq_dist.values)\n",
    "    plt.title(f'Frequency Distribution of {rain_col}')\n",
    "    plt.xlabel(rain_col)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Seasonality analysis\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.strftime('%b')\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    sns.countplot(x=\"year\", hue=rain_col, data=data, ax=axs[0])\n",
    "    sns.countplot(x=\"month\", hue=rain_col, data=data, ax=axs[1])\n",
    "    axs[0].set_title('Yearly Distribution of Rainfall Intensity')\n",
    "    axs[1].set_title('Monthly Distribution of Rainfall Intensity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation (Sigma Limits + Events Discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_limits(data, rain_col, sigma=3):\n",
    "    \"\"\"\n",
    "    Calculate the upper and lower sigma limits for the data and classify rain intensity.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing the data.\n",
    "        rain_col (str): Name of the column containing rainfall amounts.\n",
    "        sigma (int): Number of standard deviations to use for the limits.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column classifying rain intensity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the data\n",
    "    # mean = data[rain_col].mean()\n",
    "    # std_dev = data[rain_col].std()\n",
    "\n",
    "    mean = data[data[rain_col] > 0][rain_col].mean()\n",
    "    std_dev = data[data[rain_col] > 0][rain_col].std()\n",
    "\n",
    "    # Create a list of sigma limits\n",
    "    sigma_limits = [mean + i * std_dev for i in range(1, sigma + 1)]\n",
    "\n",
    "    # Initialize the Rain Intensity column with 'Low'\n",
    "    data['Rain Intensity'] = f'{sigma} sigma'\n",
    "\n",
    "    # Classify data points based on sigma limits, skipping the first limit\n",
    "    for i, limit in enumerate(reversed(sigma_limits)):\n",
    "        data.loc[data[rain_col] <= limit, 'Rain Intensity'] = f'{sigma - i} sigma'\n",
    "\n",
    "    data.loc[data[rain_col] == 0, 'Rain Intensity'] = 'No-Rainfall'\n",
    "\n",
    "    return data, sigma_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "In this section we would use machine learning for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(rainfall_data, target_col, sequence_length=24, test_size=0.3, epochs=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train an LSTM model on categorical rainfall data.\n",
    "\n",
    "    Parameters:\n",
    "        rainfall_data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        target_col (str): Name of the target column (categorical rainfall levels).\n",
    "        sequence_length (int): Length of the sequences for LSTM input.\n",
    "        test_size (float): Proportion of the data to be used as the test set.\n",
    "        epochs (int): Number of epochs to train the model.\n",
    "        batch_size (int): Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): Trained LSTM model.\n",
    "        history (History): Training history.\n",
    "        label_encoder (LabelEncoder): Label encoder for decoding predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Encode categorical rainfall labels\n",
    "    label_encoder = LabelEncoder().fit(rainfall_data[target_col])\n",
    "    encoded_sequences = label_encoder.transform(rainfall_data[target_col])\n",
    "\n",
    "    # Function to create sequences\n",
    "    def create_sequences(data, seq_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            X.append(data[i:i + seq_length])  # Use the encoded rainfall category\n",
    "            y.append(data[i + seq_length])   # Predict the next value\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # Prepare sequences for LSTM\n",
    "    X, y = create_sequences(encoded_sequences, sequence_length)\n",
    "\n",
    "    # Convert y to categorical\n",
    "    y = to_categorical(y, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # Compute Class Weights\n",
    "    y_train_labels = np.argmax(y_train, axis=1)  # Convert one-hot back to single labels\n",
    "    classes = np.unique(y_train_labels)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_labels)\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "    print(\"Computed Class Weights:\", class_weight_dict)\n",
    "\n",
    "    vocab_size = len(label_encoder.classes_)\n",
    "    # Build LSTM model\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=1),\n",
    "        LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(y.shape[1], activation='softmax')  # Output layer for classification\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Precision(name='precision'), \n",
    "                                                                              tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(X_val, y_val), class_weight=class_weight_dict)\n",
    "    \n",
    "    return model, history, label_encoder, (X_test, y_test)\n",
    "\n",
    "\n",
    "def plot_training_metrics(history):\n",
    "        \"\"\"\n",
    "        Plot training loss, precision, and recall from the training history.\n",
    "\n",
    "        Parameters:\n",
    "            history (History): Training history object containing metrics.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(13, 4))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history.history['precision'], label='Training Precision')\n",
    "        plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "        plt.title('Model Precision')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history.history['recall'], label='Training Recall')\n",
    "        plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "        plt.title('Model Recall')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.legend()\n",
    "\n",
    "        return fig\n",
    "\n",
    "def model_confusion_matrix(model, X_test, y_test, label_encoder, hot_encoding=True):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance and display confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "        model (Sequential): Trained LSTM model.\n",
    "        X_test (np.ndarray): Test data features.\n",
    "        y_test (np.ndarray): Test data labels (one-hot encoded).\n",
    "        label_encoder (LabelEncoder): Label encoder for decoding predictions.\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hot_encoding:\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)  # Convert one-hot encoding to class labels\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "    else:\n",
    "        y_pred_classes, y_true = y_pred, y_test\n",
    "\n",
    "    # Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax)\n",
    "    plt.title(\"Confusion Matrix for Rainfall Prediction\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_rainfall_category_predictions(model, testing_data, label_encoder, horizon = 24, event_index = 0, hot_encoding=True):\n",
    "    \"\"\"\n",
    "    Generate and return a rainfall-category time-series plot.\n",
    "\n",
    "    Parameters:\n",
    "        model (keras.Model): Trained classifier with a .predict() method.\n",
    "        testing_data (tuple[np.ndarray, np.ndarray]): `X_test`, `y_test` — features and one-hot targets for all test samples.\n",
    "        label_encoder (LabelEncoder): Fitted encoder to convert class indices ↔ string labels.\n",
    "        horizon (int): Number of consecutive time steps to plot, default 24.\n",
    "        event_index (int): Starting index of the plotted window within the test set, default 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Slice test window\n",
    "    X_test, y_test = testing_data\n",
    "    X_win = X_test[event_index : event_index + horizon]\n",
    "    y_win = y_test[event_index : event_index + horizon]\n",
    "\n",
    "    # Predictions → class indices\n",
    "    y_pred_probs = model.predict(X_win)\n",
    "    if hot_encoding:\n",
    "        y_pred_cls = np.argmax(y_pred_probs, axis=1)\n",
    "        y_true_cls = np.argmax(y_win, axis=1)\n",
    "    else:\n",
    "        y_pred_cls, y_true_cls = y_pred_probs, y_win\n",
    "\n",
    "    # Convert indices → categorical labels\n",
    "    pred_labels = label_encoder.inverse_transform(y_pred_cls)\n",
    "    true_labels = label_encoder.inverse_transform(y_true_cls)\n",
    "\n",
    "    # Assemble DataFrame for convenience\n",
    "    df = pd.DataFrame(\n",
    "        {\"Time Step\": range(horizon), \"Actual\": true_labels, \"Predicted\": pred_labels}\n",
    "    )\n",
    "\n",
    "    # Ordering & numeric mapping for plotting\n",
    "    # category_order = list(label_encoder.classes_)\n",
    "    category_order = [\"No-Rainfall\", \"1 sigma\", \"2 sigma\", \"3 sigma\"]\n",
    "    cat_map = {cat: idx for idx, cat in enumerate(category_order)}\n",
    "    df[\"Actual\"] = pd.Categorical(df[\"Actual\"], categories=category_order, ordered=True)\n",
    "    df[\"Predicted\"] = pd.Categorical(\n",
    "        df[\"Predicted\"], categories=category_order, ordered=True\n",
    "    )\n",
    "\n",
    "    actual_num = df[\"Actual\"].map(cat_map)\n",
    "    pred_num = df[\"Predicted\"].map(cat_map)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(df[\"Time Step\"], pred_num, label=\"Predicted\", color=\"red\")\n",
    "    ax.plot(df[\"Time Step\"], actual_num, label=\"Actual\", color=\"black\")\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"Time (hr)\",\n",
    "        ylabel=\"Rainfall Category\",\n",
    "        yticks=range(len(category_order)),\n",
    "        yticklabels=category_order,\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.grid(linestyle=\"--\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_model(rainfall_data, target_col, sequence_length=24, test_size=0.3, epochs=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train a CNN model on categorical rainfall data.\n",
    "\n",
    "    Parameters:\n",
    "        rainfall_data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        target_col (str): Name of the target column (categorical rainfall levels).\n",
    "        sequence_length (int): Length of the input sequences.\n",
    "        test_size (float): Fraction of data to use for testing.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Training batch size.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): Trained CNN model.\n",
    "        history (History): Training history.\n",
    "        label_encoder (LabelEncoder): Fitted label encoder.\n",
    "        (X_test, y_test): Test dataset for evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encode categorical target\n",
    "    label_encoder = LabelEncoder().fit(rainfall_data[target_col])\n",
    "    encoded = label_encoder.transform(rainfall_data[target_col])\n",
    "\n",
    "    # Create sequences\n",
    "    def create_sequences(data, seq_len):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_len):\n",
    "            X.append(data[i:i + seq_len])\n",
    "            y.append(data[i + seq_len])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X, y = create_sequences(encoded, sequence_length)\n",
    "    y = to_categorical(y, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "    # Reshape for Conv1D input: (samples, timesteps, channels)\n",
    "    X = X[..., np.newaxis]  # shape: (n_samples, seq_len, 1)\n",
    "\n",
    "    # Split into train/val/test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # Compute class weights\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    classes = np.unique(y_train_labels)\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train_labels)\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    print(\"Computed Class Weights:\", class_weight_dict)\n",
    "\n",
    "    vocab_size = len(label_encoder.classes_)\n",
    "    # Build CNN model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(sequence_length, 1)),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(y.shape[1], activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    return model, history, label_encoder, (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree_model(rainfall_data, target_col, sequence_length=24, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Train a Random Forest classifier on categorical rainfall data using lagged features.\n",
    "\n",
    "    Args:\n",
    "        rainfall_data (pd.DataFrame): DataFrame containing the rainfall data.\n",
    "        target_col (str): Name of the target column (categorical rainfall levels).\n",
    "        sequence_length (int, optional): Number of lagged time steps to use as features. Defaults to 5.\n",
    "        test_size (float, optional): Fraction of data to use for testing. Defaults to 0.3.\n",
    "\n",
    "    Returns:\n",
    "        model (RandomForestClassifier): Trained Random Forest model.\n",
    "        label_encoder (LabelEncoder): Fitted label encoder for the target.\n",
    "        (X_test, y_test) (tuple): Test features and true labels.\n",
    "        y_pred (np.ndarray): Predicted labels for the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encode categorical target\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded = label_encoder.fit_transform(rainfall_data[target_col])\n",
    "    \n",
    "    # Create sequences\n",
    "    def create_sequences(data, seq_len):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_len):\n",
    "            X.append(data[i:i + seq_len])  # lag features\n",
    "            y.append(data[i + seq_len])    # target: next step\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X, y = create_sequences(encoded, sequence_length)\n",
    "    \n",
    "    # Split into train/val/test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "    \n",
    "    # Fit Random Forest\n",
    "    model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    return model, label_encoder, (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods - Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data - Rainfall Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize event_data as an empty DataFrame\n",
    "rainfall_data = concat_data(data_folder)\n",
    "# analyze_data(rainfall_data, time_col=\"Date/Time (LST)\", feature_cols=[\"Temp (°C)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\", \"Precip. Amount (mm)\", \"Wind Dir (10s deg)\", \"Wind Spd (km/h)\", \"Visibility (km)\", \"Stn Press (kPa)\", \"Hmdx\", \"Wind Chill\", \"Weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "clean_data() got an unexpected keyword argument 'rain_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clean_rainfall_data \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrainfall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate/Time (LST)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrain_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrecip. Amount (mm)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_outliers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m inference(clean_rainfall_data, rain_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecip. Amount (mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: clean_data() got an unexpected keyword argument 'rain_col'"
     ]
    }
   ],
   "source": [
    "clean_rainfall_data = clean_data(rainfall_data, time_col=\"Date/Time (LST)\", feature_cols=[\"Temp (°C)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\", \"Precip. Amount (mm)\", \"Wind Dir (10s deg)\", \"Wind Spd (km/h)\", \"Visibility (km)\", \"Stn Press (kPa)\", \"Hmdx\", \"Wind Chill\", \"Weather\"], remove_outliers=True)\n",
    "inference(clean_rainfall_data, rain_col=\"Precip. Amount (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data - Rainfall Hourly - With no Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize event_data as an empty DataFrame\n",
    "rainfall_data = concat_data(data_folder)\n",
    "rainfall_data = rainfall_data[rainfall_data[\"Precip. Amount (mm)\"] > 0]\n",
    "analyze_data(rainfall_data, time_col=\"Date/Time (LST)\", rain_col=\"Precip. Amount (mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rainfall_data = clean_data(rainfall_data, time_col=\"Date/Time (LST)\", rain_col=\"Precip. Amount (mm)\", remove_outliers=True)\n",
    "inference(clean_rainfall_data, rain_col=\"Precip. Amount (mm)\", using_decompose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hourly Rain no zeros + sigma limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize event_data as an empty DataFrame\n",
    "rainfall_data = concat_data(data_folder)\n",
    "clean_rainfall_data = clean_data(rainfall_data, time_col=\"Date/Time (LST)\", rain_col=\"Precip. Amount (mm)\", remove_outliers=True)\n",
    "classed_data, sigma_limit = sigma_limits(clean_rainfall_data, rain_col=\"Precip. Amount (mm)\", sigma=3)\n",
    "inference_categorical(classed_data, rain_col=\"Rain Intensity\")\n",
    "\n",
    "# Plot all sigma classes\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Define colors for sigma classes\n",
    "colors = {'1 sigma': 'blue', '2 sigma': 'orange', '3 sigma': 'red'}\n",
    "\n",
    "# Plot the data points with different colors based on their sigma class\n",
    "for sigma_class, color in colors.items():\n",
    "    if sigma_class == \"No-Rainfall\":\n",
    "        continue\n",
    "    subset = classed_data[classed_data['Rain Intensity'] == sigma_class]\n",
    "    plt.scatter(subset.index, subset['Precip. Amount (mm)'], label=sigma_class, color=color, marker='x')\n",
    "    \n",
    "# Plot the mean line\n",
    "mean = classed_data[classed_data[\"Precip. Amount (mm)\"] > 0][\"Precip. Amount (mm)\"].mean()\n",
    "plt.axhline(mean, color='r', linestyle='--', label=f'Mean: {mean:.2f} mm')\n",
    "\n",
    "# Fill regions for low, moderate, and extreme rainfall\n",
    "plt.fill_between(classed_data.index, 0, sigma_limit[0], color='green', alpha=0.2, label='Low Rainfall')\n",
    "plt.fill_between(classed_data.index, sigma_limit[0], sigma_limit[1], color='yellow', alpha=0.2, label='Moderate Rainfall')\n",
    "plt.fill_between(classed_data.index, sigma_limit[1], classed_data[\"Precip. Amount (mm)\"].max(), color='red', alpha=0.2, label='Extreme Rainfall')\n",
    "\n",
    "plt.title('Precipitation Amount by Sigma Class')\n",
    "plt.xlabel('Date/Time (LST)')\n",
    "plt.ylabel('Precip. Amount (mm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long short term memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mlflow server and experiment parameters\n",
    "mlflow.set_tracking_uri(uri=\"./mlruns\")\n",
    "mlflow.set_experiment(\"LSTM-Rainfall-Prediction\")\n",
    "\n",
    "# logging\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.keras.autolog()\n",
    "\n",
    "    # LSTM model\n",
    "    model, history, label_encoder, testing_data = train_lstm_model(classed_data, \"Rain Intensity\", \n",
    "                                                sequence_length=32, test_size=0.2,\n",
    "                                                epochs=200, batch_size=25)\n",
    "    \n",
    "    # Plot training metrics\n",
    "    fig = plot_training_metrics(history)\n",
    "    mlflow.log_figure(fig, \"training_metrics.png\")\n",
    "    \n",
    "    # Confuseion matrix\n",
    "    cm = model_confusion_matrix(model, *testing_data, label_encoder)\n",
    "    mlflow.log_figure(cm, \"confusion_matrix.png\")\n",
    "\n",
    "    # Plot rainfall category predictions\n",
    "    fig = plot_rainfall_category_predictions(model, testing_data, label_encoder, horizon=24, event_index=6178)\n",
    "    mlflow.log_figure(fig, \"rainfall_category_predictions.png\")\n",
    "\n",
    "# run command <mlflow ui> in terminal to check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mlflow server and experiment parameters\n",
    "mlflow.set_tracking_uri(uri=\"./mlruns\")\n",
    "mlflow.set_experiment(\"CNN-Rainfall-Prediction\")\n",
    "\n",
    "# logging\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.keras.autolog()\n",
    "\n",
    "    # CNN model\n",
    "    model, history, label_encoder, testing_data = train_cnn_model(classed_data, \"Rain Intensity\",\n",
    "                                                sequence_length=32, test_size=0.2,\n",
    "                                                epochs=200, batch_size=100)\n",
    "    \n",
    "    # Plot training metrics\n",
    "    fig = plot_training_metrics(history)\n",
    "    mlflow.log_figure(fig, \"training_metrics.png\")\n",
    "    \n",
    "    # Confuseion matrix\n",
    "    cm = model_confusion_matrix(model, *testing_data, label_encoder)\n",
    "    mlflow.log_figure(cm, \"confusion_matrix.png\")\n",
    "\n",
    "    # Plot rainfall category predictions\n",
    "    fig = plot_rainfall_category_predictions(model, testing_data, label_encoder, horizon=24, event_index=6178)\n",
    "    mlflow.log_figure(fig, \"rainfall_category_predictions.png\")\n",
    "\n",
    "# run command <mlflow ui> in terminal to check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "## mlflow server and experiment parameters\n",
    "mlflow.set_tracking_uri(uri=\"./mlruns\")\n",
    "mlflow.set_experiment(\"RF-Rainfall-Prediction\")\n",
    "\n",
    "# logging\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # RF model\n",
    "    model, label_encoder, testing_data = train_tree_model(classed_data, \"Rain Intensity\", \n",
    "                                                          sequence_length=32, test_size=0.2)\n",
    "    \n",
    "    # Confuseion matrix\n",
    "    cm = model_confusion_matrix(model, *testing_data, label_encoder, hot_encoding=False)\n",
    "    mlflow.log_figure(cm, \"confusion_matrix.png\")\n",
    "\n",
    "    # Plot rainfall category predictions\n",
    "    fig = plot_rainfall_category_predictions(model, testing_data, label_encoder, horizon=24, event_index=6178, hot_encoding=False)\n",
    "    mlflow.log_figure(fig, \"rainfall_category_predictions.png\")\n",
    "\n",
    "# run command <mlflow ui> in terminal to check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication Plot (PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "# Use LaTeX for text rendering\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"font.size\": 14,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "})\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, rain_col = classed_data, \"Rain Intensity\"\n",
    "# Frequency distribution of categorical data\n",
    "freq_dist = data[rain_col].value_counts(normalize=True)\n",
    "\n",
    "# Plot frequency distribution with dark colors and values on top of sigma 2 and sigma 3 classes\n",
    "plt.figure(figsize=(7, 6))\n",
    "bars = plt.bar(freq_dist.index, freq_dist.values, color=['black', 'dimgray', 'darkgray', 'gray'], width=0.5)\n",
    "plt.xlabel(rain_col)\n",
    "plt.ylabel('Proportion')\n",
    "\n",
    "# Add values on top of sigma 2 and sigma 3 classes\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    if bar.get_x() + bar.get_width() / 2 in [freq_dist.index.get_loc('2 sigma'), freq_dist.index.get_loc('3 sigma')]:\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height+0.01, f'{height:.3}', ha='center', va='bottom', color='black')\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"Rainfall_Frequency_Distribution.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all sigma classes\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Define colors for sigma classes\n",
    "colors = {'1 sigma': 'blue', '2 sigma': 'orange', '3 sigma': 'red'}\n",
    "\n",
    "# Filter data for the year 2024\n",
    "classed_data_2024 = classed_data[classed_data['year'] == 2018]\n",
    "\n",
    "# Plot the data points with different colors based on their sigma class\n",
    "for sigma_class, color in colors.items():\n",
    "    if sigma_class == \"No-Rainfall\":\n",
    "        continue\n",
    "    subset = classed_data_2024[classed_data_2024['Rain Intensity'] == sigma_class]\n",
    "    plt.scatter(subset.index, subset['Precip. Amount (mm)'], color=\"lightgray\", marker='.')\n",
    "\n",
    "# Plot the mean line\n",
    "mean = classed_data[classed_data[\"Precip. Amount (mm)\"] > 0][\"Precip. Amount (mm)\"].mean()\n",
    "plt.axhline(mean, color='r', linestyle='--', label=f'Mean={mean:.2f} mm/h')\n",
    "\n",
    "# Fill regions for low, moderate, and extreme rainfall as horizontal lines\n",
    "plt.axhline(y=sigma_limit[0], color='green', linestyle='-', linewidth=1)\n",
    "plt.axhline(y=sigma_limit[1], color='darkgoldenrod', linestyle='-', linewidth=1)\n",
    "\n",
    "\n",
    "x_pos = classed_data_2024.index.min()\n",
    "x_pos_plus = classed_data_2024.index[250]\n",
    "\n",
    "# Text annotations with bold text using `fontsize` and `weight`\n",
    "# Add text annotations with bold text inside a box using `bbox`\n",
    "plt.annotate(r'$\\sigma$ (Low)', xy=(x_pos_plus, mean), xytext=(x_pos_plus, mean + 0.65),\n",
    "             textcoords='data', color='green', ha='left', va='bottom',\n",
    "             fontsize=14, weight='heavy', family='sans-serif',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='green', facecolor='white'))\n",
    "\n",
    "plt.annotate(r'$2\\sigma$ (Moderate)', xy=(x_pos_plus, sigma_limit[0]), xytext=(x_pos_plus, sigma_limit[0] + 0.65),\n",
    "             textcoords='data', color='darkgoldenrod', ha='left', va='bottom',\n",
    "             fontsize=14, weight='heavy', family='sans-serif',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='darkgoldenrod', facecolor='white'))\n",
    "\n",
    "plt.annotate(r'$3 \\sigma$ (Extreme)', xy=(x_pos_plus, sigma_limit[1]), xytext=(x_pos_plus, sigma_limit[1] + 3.5),\n",
    "             textcoords='data', color='red', ha='left', va='bottom',\n",
    "             fontsize=14, weight='heavy', family='sans-serif',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='red', facecolor='white'))\n",
    "\n",
    "\n",
    "# Add vertical double-headed arrows between the axhlines and text\n",
    "plt.annotate('', xy=(x_pos, mean), xytext=(x_pos, sigma_limit[0]),\n",
    "             arrowprops=dict(arrowstyle='<|-|>', color='black'))\n",
    "plt.annotate('', xy=(x_pos, sigma_limit[0]), xytext=(x_pos, sigma_limit[1]),\n",
    "             arrowprops=dict(arrowstyle='<|-|>', color='black'))\n",
    "plt.annotate('', xy=(x_pos, sigma_limit[1]), xytext=(x_pos, classed_data_2024[\"Precip. Amount (mm)\"].max()),\n",
    "             arrowprops=dict(arrowstyle='<|-|>', color='black'))\n",
    "\n",
    "\n",
    "plt.xlabel('Time (hr)')\n",
    "plt.xticks(ticks=plt.xticks()[0][::3])  # Reduce the number of tick labels by showing every 10th tick\n",
    "plt.ylabel('Precipitation (mm/hr)')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"Rainfall_Sigma_Classes.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='black', linestyle='-')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='yellowgreen', linestyle='-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"LSTM_Loss.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(history.history['precision'], label='Training Precision', color='black', linestyle='-')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision', color='yellowgreen', linestyle='-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"LSTM_Precision.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(history.history['recall'], label='Training Recall', color='black', linestyle='-')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall', color='yellowgreen', linestyle='-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"LSTM_Recall.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_rainfall_category_predictions(model, testing_data, label_encoder, horizon=24, event_index=6178)\n",
    "\n",
    "plt.savefig(Path(results_folder).joinpath(\"LSTM_Testing.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
